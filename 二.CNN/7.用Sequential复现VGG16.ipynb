{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "395e4621",
   "metadata": {},
   "source": [
    "一.VGG16复现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd54adc5",
   "metadata": {},
   "source": [
    "VGG网络结构特点\n",
    "\n",
    "卷积层设计：\n",
    "\n",
    "统一卷积核尺寸：VGG 模型大量使用 3×3 的小卷积核，这是它的一大标志性特点。相比于大尺寸卷积核（如 5×5、7×7 ），3×3 卷积核有两个主要优势。一方面，多个 3×3 卷积核堆叠的效果可以近似替代大卷积核，且参数量更少。比如，两个 3×3 卷积核堆叠相当于一个 5×5 卷积核的感受野，但参数量从 5×5× 输入通道数 × 输出通道数，减少到了（3×3× 输入通道数 × 中间通道数）+（3×3× 中间通道数 × 输出通道数）；另一方面，3×3 卷积核能更好地保留图像的细节信息，且增加了网络的非线性表达能力，因为每一个卷积层后都可以添加激活函数 。\n",
    "\n",
    "固定步长和填充：卷积层通常使用步长为 1，填充为 1 的设置，这样可以保证在进行卷积操作后，特征图的尺寸保持不变（计算公式：输出尺寸 = (输入尺寸 - 卷积核尺寸 + 2× 填充) / 步长 + 1，当卷积核为 3×3、步长为 1、填充为 1 时，输出尺寸等于输入尺寸 ）。\n",
    "\n",
    "池化层设计：在连续的几个卷积层之后，会跟一个最大池化层，池化核大小为 2×2，步长为 2。通过池化操作，特征图的尺寸会减半，这样逐步降低特征图的空间维度，同时增加特征图的通道数，使网络能够学习到更高级的语义信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff925c17",
   "metadata": {},
   "source": [
    "![](https://skojiangdoc.oss-cn-beijing.aliyuncs.com/2021PyTorchDL/WEEK9/7.png?versionId=CAEQFRiBgMD2zKyfxxciIGZhMDQ0Y2UyYTA5ZjQ1NjhhMWNjNDQ1Njg3YTFiODZh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b90535ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "48c1dca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features_ = nn.Sequential(nn.Conv2d(3,64,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(64,64,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(64,128,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(128,128,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(128,256,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(256,256,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(256,256,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(256,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                      )\n",
    "        self.clf_ = nn.Sequential(nn.Dropout(0.5)\n",
    "                                  ,nn.Linear(512*7*7,4096),nn.ReLU(inplace=True)\n",
    "                                  ,nn.Dropout(0.5)\n",
    "                                  ,nn.Linear(4096,4096),nn.ReLU(inplace=True)\n",
    "                                  ,nn.Linear(4096,1000),nn.Softmax(dim=1)\n",
    "                                 )\n",
    "    \n",
    "    # [10, 512, 7, 7]\n",
    "    def forward(self,x):\n",
    "        x = self.features_(x) #用特征提取的架构提取特征\n",
    "        x = x.view(-1,512*7*7) #调整数据结构，拉平数据\n",
    "        output = self.clf_(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e3bc9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VGG16                                    [10, 1000]                --\n",
       "├─Sequential: 1-1                        [10, 512, 7, 7]           --\n",
       "│    └─Conv2d: 2-1                       [10, 64, 224, 224]        1,792\n",
       "│    └─ReLU: 2-2                         [10, 64, 224, 224]        --\n",
       "│    └─Conv2d: 2-3                       [10, 64, 224, 224]        36,928\n",
       "│    └─ReLU: 2-4                         [10, 64, 224, 224]        --\n",
       "│    └─MaxPool2d: 2-5                    [10, 64, 112, 112]        --\n",
       "│    └─Conv2d: 2-6                       [10, 128, 112, 112]       73,856\n",
       "│    └─ReLU: 2-7                         [10, 128, 112, 112]       --\n",
       "│    └─Conv2d: 2-8                       [10, 128, 112, 112]       147,584\n",
       "│    └─ReLU: 2-9                         [10, 128, 112, 112]       --\n",
       "│    └─MaxPool2d: 2-10                   [10, 128, 56, 56]         --\n",
       "│    └─Conv2d: 2-11                      [10, 256, 56, 56]         295,168\n",
       "│    └─ReLU: 2-12                        [10, 256, 56, 56]         --\n",
       "│    └─Conv2d: 2-13                      [10, 256, 56, 56]         590,080\n",
       "│    └─ReLU: 2-14                        [10, 256, 56, 56]         --\n",
       "│    └─Conv2d: 2-15                      [10, 256, 56, 56]         590,080\n",
       "│    └─ReLU: 2-16                        [10, 256, 56, 56]         --\n",
       "│    └─MaxPool2d: 2-17                   [10, 256, 28, 28]         --\n",
       "│    └─Conv2d: 2-18                      [10, 512, 28, 28]         1,180,160\n",
       "│    └─ReLU: 2-19                        [10, 512, 28, 28]         --\n",
       "│    └─Conv2d: 2-20                      [10, 512, 28, 28]         2,359,808\n",
       "│    └─ReLU: 2-21                        [10, 512, 28, 28]         --\n",
       "│    └─Conv2d: 2-22                      [10, 512, 28, 28]         2,359,808\n",
       "│    └─ReLU: 2-23                        [10, 512, 28, 28]         --\n",
       "│    └─MaxPool2d: 2-24                   [10, 512, 14, 14]         --\n",
       "│    └─Conv2d: 2-25                      [10, 512, 14, 14]         2,359,808\n",
       "│    └─ReLU: 2-26                        [10, 512, 14, 14]         --\n",
       "│    └─Conv2d: 2-27                      [10, 512, 14, 14]         2,359,808\n",
       "│    └─ReLU: 2-28                        [10, 512, 14, 14]         --\n",
       "│    └─Conv2d: 2-29                      [10, 512, 14, 14]         2,359,808\n",
       "│    └─ReLU: 2-30                        [10, 512, 14, 14]         --\n",
       "│    └─MaxPool2d: 2-31                   [10, 512, 7, 7]           --\n",
       "├─Sequential: 1-2                        [10, 1000]                --\n",
       "│    └─Dropout: 2-32                     [10, 25088]               --\n",
       "│    └─Linear: 2-33                      [10, 4096]                102,764,544\n",
       "│    └─ReLU: 2-34                        [10, 4096]                --\n",
       "│    └─Dropout: 2-35                     [10, 4096]                --\n",
       "│    └─Linear: 2-36                      [10, 4096]                16,781,312\n",
       "│    └─ReLU: 2-37                        [10, 4096]                --\n",
       "│    └─Linear: 2-38                      [10, 1000]                4,097,000\n",
       "│    └─Softmax: 2-39                     [10, 1000]                --\n",
       "==========================================================================================\n",
       "Total params: 138,357,544\n",
       "Trainable params: 138,357,544\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 154.84\n",
       "==========================================================================================\n",
       "Input size (MB): 6.02\n",
       "Forward/backward pass size (MB): 1084.54\n",
       "Params size (MB): 553.43\n",
       "Estimated Total Size (MB): 1643.99\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=VGG16()\n",
    "summary(net,input_size=(10,3,224,224),device=\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2cc86d",
   "metadata": {},
   "source": [
    "用于确定输入线性层之前的特征数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c6baa27b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 512, 7, 7])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=torch.ones(size=(10,3,224,224))\n",
    "net = nn.Sequential(nn.Conv2d(3,64,3,padding=1),\n",
    "                    nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(64,64,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(64,128,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(128,128,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(128,256,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(256,256,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(256,256,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(256,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                       \n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.Conv2d(512,512,3,padding=1),nn.ReLU(inplace=True)\n",
    "                                       ,nn.MaxPool2d(2)\n",
    "                                      )\n",
    "net(data).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jrx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
