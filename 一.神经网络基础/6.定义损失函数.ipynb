{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616f4436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7423)\n",
      "tensor(87.1135)\n"
     ]
    }
   ],
   "source": [
    "#1.1定义损失函数\n",
    "import torch\n",
    "from torch.nn import MSELoss \n",
    "yhat=torch.randn(size=(50,),dtype=torch.float32 )\n",
    "y=torch.randn(size=(50,),dtype=torch.float32)\n",
    "#默认均方误差\n",
    "criterion1=MSELoss()\n",
    "loss1=criterion1(yhat,y)\n",
    "print(loss1)\n",
    "#整体误差\n",
    "criterion2=MSELoss(reduction=\"sum\")\n",
    "loss2=criterion2(yhat,y)\n",
    "print(loss2)\n",
    "#MSELoss(reduction=\"sum\")#选择是均方误差还是整体误差：reduction=\"mean\"/\"sum\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37faf6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7740)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.2二分类交叉熵损失函数\n",
    "import torch\n",
    "m = 3*pow(10,4)  # 样本数量：30,000\n",
    "torch.random.manual_seed(420)  # 设置随机种子保证可重复性\n",
    "X = torch.rand(size=(m,4), dtype=torch.float32)  # 生成输入特征矩阵 [30000,4]\n",
    "w = torch.rand(size=(4,1), dtype=torch.float32)  # 生成权重矩阵 [4,1]\n",
    "y = torch.randint(low=0, high=2, size=(m,1), dtype=torch.float32)  # 生成二分类标签 [30000,1]\n",
    "yhat = torch.mm(X,w)  # 矩阵乘法计算预测值 [30000,1]\n",
    "sigma = torch.sigmoid(yhat)  # 应用sigmoid激活函数\n",
    "# 计算对数损失\n",
    "loss = -(1/m)*torch.sum((y*torch.log(sigma)+(1-y)*torch.log(1-sigma)))\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b36c460",
   "metadata": {},
   "source": [
    "BCEWithLogitsLoss内置了sigmoid函数与交叉熵函数，它会自动计算输入值的sigmoid值，因此需要输入\n",
    "zhat与真实标签，且顺序不能变化，zhat必须在前。\n",
    "\n",
    "相对的，BCELoss中只有交叉熵函数，没有sigmoid层，因此需要输入sigma与真实标签，且顺序不能变\n",
    "化。\n",
    "\n",
    "同时，这两个函数都要求预测值与真实标签的数据类型以及结构（shape）必须相同，否则运行就会报"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf2f9c2",
   "metadata": {},
   "source": [
    "1. nn.BCELoss() (Binary Cross Entropy Loss)\n",
    "使用条件：\n",
    "输入：必须已经经过Sigmoid激活（值在[0,1]之间）\n",
    "2. nn.BCEWithLogitsLoss() (BCE with Sigmoid Built-in)\n",
    "使用条件：\n",
    "输入：直接使用线性层的原始输出（logits）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08cea1b",
   "metadata": {},
   "source": [
    "function F.binary_cross_entropy_with_logits\n",
    "\n",
    "function F.binary_cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cabaa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7740)\n",
      "tensor(0.7740)\n"
     ]
    }
   ],
   "source": [
    "#不同\n",
    "import torch.nn as nn\n",
    "criterion1=nn.BCELoss()#实例化\n",
    "loss1=criterion1(sigma,y)\n",
    "print(loss1)\n",
    "criterion2=nn.BCEWithLogitsLoss()#实例化\n",
    "loss2=criterion2(yhat,y)\n",
    "print(loss2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd506a",
   "metadata": {},
   "source": [
    "调用logsoftmax和NLLLoss实现\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ff644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1556)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.3多分类交叉熵损失-1\n",
    "import torch  # 导入PyTorch库\n",
    "from torch import nn  # 导入神经网络模块\n",
    "\n",
    "# 1. 数据准备部分\n",
    "m = 3*pow(10,4)  # 定义样本数量：30,000个\n",
    "torch.random.manual_seed(420)  # 设置随机种子为420，保证结果可复现\n",
    "\n",
    "# 生成输入特征矩阵，形状为[30000,4]，即30000个样本，每个样本4个特征\n",
    "X = torch.rand(size=(m,4), dtype=torch.float32)\n",
    "\n",
    "# 生成权重矩阵，形状为[4,3]，将4维特征映射到3个类别输出\n",
    "w = torch.rand(size=(4,3), dtype=torch.float32)\n",
    "\n",
    "# 生成标签向量，形状为[30000]，每个元素取值0/1/2表示3个类别\n",
    "y = torch.randint(low=0, high=3, size=(m,), dtype=torch.float32)\n",
    "\n",
    "# 2. 前向计算部分\n",
    "# 矩阵乘法计算预测值：[30000,4] @ [4,3] → [30000,3]\n",
    "# 得到的yhat是\"logits\"（未归一化的原始分数）\n",
    "yhat = torch.mm(X,w)\n",
    "\n",
    "# 3. 损失计算部分\n",
    "# 实例化LogSoftmax层，dim=1表示对每行的3个类别分数进行操作\n",
    "logsm = nn.LogSoftmax(dim=1)\n",
    "\n",
    "# 对预测值yhat计算log-softmax\n",
    "# 公式：log(exp(x_i)/∑exp(x_j))，结果形状仍为[30000,3]\n",
    "logsigma = logsm(yhat)\n",
    "\n",
    "# 实例化负对数似然损失(NLLLoss)\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# 计算损失：需要log-softmax结果和类别索引标签\n",
    "# y.long()确保标签是整数类型\n",
    "loss = criterion(logsigma, y.long())\n",
    "print(loss)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f67d4f",
   "metadata": {},
   "source": [
    "直接调用CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6bcef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1556)\n"
     ]
    }
   ],
   "source": [
    "#-2\n",
    "# 损失计算\n",
    "criterion = nn.CrossEntropyLoss()  # 实例化损失函数 #crossEn(reduction=\"mean\"/\"sum\"/\"none\")\n",
    "loss = criterion(yhat, y.long())  # 正确调用：传入预测值和标签\n",
    "print( loss)\n",
    "#\n",
    "# 1. LogSoftmax 定义：对输入张量应用 对数softmax 操作，即先对输入进行 softmax（将值映射到概率分布），再对结果取对数。\n",
    "# 2. NLLLoss 定义：计算负对数似然损失。输入是对数概率（如 LogSoftmax 的输出），目标是对应的类别标签。\n",
    "# 3. CrossEntropyLoss 定义：结合了 LogSoftmax + NLLLoss 的一步操作。直接对原始logits计算交叉熵损失.\n",
    "# 特性\tCrossEntropyLoss（原始logits）；NLLLoss + LogSoftmax(用 LogSoftmax 处理）\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jrx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
